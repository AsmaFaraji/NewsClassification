{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from __future__ import unicode_literals\n",
    "from hazm import Normalizer, word_tokenize, sent_tokenize,Stemmer,Lemmatizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address = ['/Users/asma/University/DataMining/ThirdUpdateNewsDataSet/Accident/', \n",
    "          '/Users/asma/University/DataMining/ThirdUpdateNewsDataSet/Cultural/',\n",
    "          '/Users/asma/University/DataMining/ThirdUpdateNewsDataSet/Economic/',\n",
    "          '/Users/asma/University/DataMining/ThirdUpdateNewsDataSet/Political/',\n",
    "          '/Users/asma/University/DataMining/ThirdUpdateNewsDataSet/Research/',\n",
    "          '/Users/asma/University/DataMining/ThirdUpdateNewsDataSet/Science/',\n",
    "          '/Users/asma/University/DataMining/ThirdUpdateNewsDataSet/Social/',\n",
    "          '/Users/asma/University/DataMining/ThirdUpdateNewsDataSet/Sport/',\n",
    "          '/Users/asma/University/DataMining/ThirdUpdateNewsDataSet/State/',\n",
    "          '/Users/asma/University/DataMining/ThirdUpdateNewsDataSet/World/']\n",
    "damnword = ['این',\n",
    "            'خود'\n",
    "            , 'بود'\n",
    "            , 'دیگر'\n",
    "            ,'نیز'\n",
    "            ,'اند'\n",
    "            ,'ان'\n",
    "            ,'سال'\n",
    "            ,'گفت'\n",
    "            ,'علیه'\n",
    "            ,'روز'\n",
    "            ,'زیاد'\n",
    "            ,'هنوز'\n",
    "            ,'زاده'\n",
    "            ,'اما'\n",
    "            ,'چنین'\n",
    "            ,'پیش'\n",
    "            ,'کامل'\n",
    "            ,'ابتدا'\n",
    "            ,'ولی'\n",
    "            ,'داشت'\n",
    "            ,'افزود'\n",
    "            ,'بزرگ'\n",
    "            ,'همه'\n",
    "            ,'آقا'\n",
    "            ,'محمد'\n",
    "            ,'علی'\n",
    "            ,'میثم'\n",
    "            ,'علیه'\n",
    "            ,'حال'\n",
    "            ,'انجام'\n",
    "            ,'وجود'\n",
    "            ,'حتی'\n",
    "            ,'باره'\n",
    "            ,'شنبه'\n",
    "            ,'برجا'\n",
    "            ,'داشت'\n",
    "            ,'ممکن'\n",
    "            ,'بعضی'\n",
    "            ,'نیست'\n",
    "            ,'هستند'\n",
    "            ,'منتها'\n",
    "            ,'هیچ'\n",
    "            ,'میبیند'\n",
    "            ,'کند'\n",
    "            ,'حال'\n",
    "            ,'غیر'\n",
    "            ,'برخی'\n",
    "            ,'را'\n",
    "            ,'مگر'\n",
    "            ,'والا'\n",
    "            ,'بسیار'\n",
    "            ,'همانند'\n",
    "            ,'برد'\n",
    "            ,'گذراند'\n",
    "            ,'غیر'\n",
    "            ,'چند'\n",
    "            ,'همان'\n",
    "            ,'حتما'\n",
    "            ,'کلیه'\n",
    "            ,'لذا','کس'\n",
    "            ,'خبرنگار'\n",
    "            ,'برای'\n",
    "            ,'باش'\n",
    "            ,'همین'\n",
    "            ,'شاید'\n",
    "            ,'مند'\n",
    "            ,'فرو'\n",
    "            ,'اگر'\n",
    "            ,'ادامه'\n",
    "            ,'مثال'\n",
    "            ,'توسط'\n",
    "            ,'زیر'\n",
    "            ,'اول'\n",
    "            ,'دوم'\n",
    "            ,'سوم'\n",
    "            ,'1'\n",
    "            ,'2'\n",
    "            ,'3'\n",
    "            ,'4'\n",
    "            ,'5'\n",
    "            ,'5'\n",
    "            ,'6'\n",
    "            ,'7'\n",
    "            ,'8'\n",
    "            ,'9'\n",
    "            ,'0'\n",
    "            ,'احمد'\n",
    "            ,'+'\n",
    "            ,'بهنام'\n",
    "            ,'مریم'\n",
    "            ,'نام'\n",
    "            ,'حسن'\n",
    "            ,'مورد'\n",
    "            ,'رو'\n",
    "            ,'ترین'\n",
    "            ,'شهناز'\n",
    "            ,'حسینی'\n",
    "            ,'لیلا'\n",
    "           ]\n",
    "a = [1,2,3,5]\n",
    "for i in a:\n",
    "    i = 0\n",
    "a    \n",
    "punctuationmark = ['است','شود','شد','کرد',',','.','خواه','*','!','@','#','$','%','^','&','*','(',')','_','+','|','{',]\n",
    "len(damnword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sens = []\n",
    "for add in address:\n",
    "    normsen = pd.read_csv(add + 'normsentences.csv')\n",
    "    normsen.fillna(0,inplace=True)\n",
    "    for row in normsen.iterrows():\n",
    "        index, data = row\n",
    "        data = list(set(data.tolist()))\n",
    "        if 0 in data:\n",
    "            data.remove(0)\n",
    "        sens = sens + data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf8' codec can't decode byte 0xd9 in position 0: unexpected end of data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8b0badd6a605>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0;32mif\u001b[0m  \u001b[0mdamn\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnumeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0municode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'*'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'#'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'@'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'خواه'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'کرد'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'است'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ایرنا'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'گزارش'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'شد'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'شود'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0museless\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf8' codec can't decode byte 0xd9 in position 0: unexpected end of data"
     ]
    }
   ],
   "source": [
    "f = open('sensen.txt','wb')\n",
    "stemmer = Stemmer()\n",
    "lemmatizer = Lemmatizer()\n",
    "eachnewsword = []\n",
    "helplist = []\n",
    "allword = []\n",
    "useless = []\n",
    "allnewsword = dict()\n",
    "s = ''\n",
    "v = 0\n",
    "\n",
    "for token in sens:\n",
    "    for w in token:\n",
    "        damn = False\n",
    "        for dw in damnword:\n",
    "            if str(dw) in str(w):\n",
    "                damn = True\n",
    "        if str('های') in str(w[-3:]):\n",
    "            w = stemmer.stem(w)\n",
    "        if str('ها') in str(w[-2:]):\n",
    "            w = stemmer.stem(w)\n",
    "        if str('-') in str(w):\n",
    "            w = w.replace('-', ' ') \n",
    "        if str('_') in str(w):\n",
    "            w = w.replace('_',' ')\n",
    "        print w        \n",
    "        if  damn or unicode.isnumeric(unicode(w)) or ('*' in str(w)) or ('/' in str(w)) or ('#' in str(w)) or ('@' in str(w)) or  (len(w) <= 2) or  (str('خواه') in str(w)) or (str('کرد') in str(w))  or (str('است') in str(w)) or (str('ایرنا') in str(w)) or (str('گزارش') in str(w)) or (str('شد') in str(w)) or (str('شود') in str(w)):\n",
    "            useless.append(w)\n",
    "        else:\n",
    "            allword.append(w)\n",
    "            w = lemmatizer.lemmatize(str(w))\n",
    "            if '#' in w:\n",
    "                print w\n",
    "            helplist.append(w)\n",
    "    s = ''        \n",
    "    for vocab in helplist:\n",
    "        s = s + vocab + ' '\n",
    "    #f.write(s + '\\n')\n",
    "    helplist=[]\n",
    "len(allword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24301"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(allword)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sens = []\n",
    "for add in address:\n",
    "    normsen = pd.read_csv(add + 'normsentences.csv')\n",
    "    normsen.fillna(0,inplace=True)\n",
    "    for row in normsen.iterrows():\n",
    "        index, data = row\n",
    "        data = list(set(data.tolist()))\n",
    "        if 0 in data:\n",
    "            data.remove(0)\n",
    "        sens = sens + data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "sens = []\n",
    "for row in normsen[key].iterrows():\n",
    "    index , data = row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\xd8\\xb3\\xd8\\xb1\\xd8\\xaf\\xd8\\xa7\\xd8\\xb1, \\xd9\\x82\\xd9\\x86\\xd8\\xa8\\xd8\\xb1\\xdb\\x8c, \\xd8\\xa7\\xd9\\x81\\xd8\\xb2\\xd9\\x88\\xd8\\xaf, :, \\xdb\\xb9\\xdb\\xb0, \\xd8\\xaf\\xd8\\xb1\\xd8\\xb5\\xd8\\xaf, \\xd8\\xac\\xd8\\xb1\\xd8\\xa7\\xd8\\xa6\\xd9\\x85, \\xd8\\xac\\xd9\\x86\\xd8\\xa7\\xdb\\x8c\\xdb\\x8c, \\xd8\\xaf\\xd8\\xb1, \\xd8\\xb3\\xdb\\x8c\\xd8\\xb3\\xd8\\xaa\\xd8\\xa7\\xd9\\x86, \\xd9\\x88, \\xd8\\xa8\\xd9\\x84\\xd9\\x88\\xda\\x86\\xd8\\xb3\\xd8\\xaa\\xd8\\xa7\\xd9\\x86, \\xda\\xa9\\xd8\\xb4\\xd9\\x81, \\xd8\\xb4\\xd8\\xaf\\xd9\\x87_\\xd8\\xa7\\xd8\\xb3\\xd8\\xaa, .]'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in allnewssentence:\n",
    "    for sen in allnewssentence[key]:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
