{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "from __future__ import unicode_literals\n",
    "from hazm import Normalizer, word_tokenize, sent_tokenize\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address = ['/Users/asma/ThirdUpdateNewsDataSet/Accident/', \n",
    "          '/Users/asma/ThirdUpdateNewsDataSet/Cultural/',\n",
    "          '/Users/asma/ThirdUpdateNewsDataSet/Economic/',\n",
    "          '/Users/asma/ThirdUpdateNewsDataSet/Political/',\n",
    "          '/Users/asma/ThirdUpdateNewsDataSet/Research/',\n",
    "          '/Users/asma/ThirdUpdateNewsDataSet/Science/',\n",
    "          '/Users/asma/ThirdUpdateNewsDataSet/Social/',\n",
    "          '/Users/asma/ThirdUpdateNewsDataSet/Sport/',\n",
    "          '/Users/asma/ThirdUpdateNewsDataSet/State/',\n",
    "          '/Users/asma/ThirdUpdateNewsDataSet/World/']\n",
    "damnword = ['این',\n",
    "            'خود'\n",
    "            , 'بود'\n",
    "            , 'دیگر'\n",
    "            ,'نیز'\n",
    "            ,'اند'\n",
    "            ,'ان'\n",
    "            ,'سال'\n",
    "            ,'گفت'\n",
    "            ,'علیه'\n",
    "            ,'روز'\n",
    "            ,'زیاد'\n",
    "            ,'هنوز'\n",
    "            ,'زاده'\n",
    "            ,'اما'\n",
    "            ,'چنین'\n",
    "            ,'پیش'\n",
    "            ,'کامل'\n",
    "            ,'ابتدا'\n",
    "            ,'ولی'\n",
    "            ,'داشت'\n",
    "            ,'افزود'\n",
    "            ,'بزرگ'\n",
    "            ,'همه'\n",
    "            ,'آقا'\n",
    "            ,'محمد'\n",
    "            ,'علی'\n",
    "            ,'میثم'\n",
    "            ,'علیه'\n",
    "            ,'حال'\n",
    "            ,'انجام'\n",
    "            ,'وجود'\n",
    "            ,'حتی'\n",
    "            ,'باره'\n",
    "            ,'شنبه'\n",
    "            ,'برجا'\n",
    "            ,'داشت'\n",
    "            ,'ممکن'\n",
    "            ,'بعضی'\n",
    "            ,'نیست'\n",
    "            ,'هستند'\n",
    "            ,'منتها'\n",
    "            ,'هیچ'\n",
    "            ,'میبیند'\n",
    "            ,'کند'\n",
    "            ,'حال'\n",
    "            ,'غیر'\n",
    "            ,'برخی'\n",
    "            ,'را'\n",
    "            ,'مگر'\n",
    "            ,'والا'\n",
    "            ,'بسیار'\n",
    "            ,'همانند'\n",
    "            ,'برد'\n",
    "            ,'گذراند'\n",
    "            ,'غیر'\n",
    "            ,'چند'\n",
    "            ,'همان'\n",
    "            ,'حتما'\n",
    "            ,'کلیه'\n",
    "            ,'لذا','کس'\n",
    "            ,'خبرنگار'\n",
    "            ,'برای'\n",
    "            ,'باش'\n",
    "            ,'همین'\n",
    "            ,'شاید'\n",
    "            ,'مند'\n",
    "            ,'فرو'\n",
    "            ,'اگر'\n",
    "            ,'ادامه'\n",
    "            ,'مثال'\n",
    "            ,'توسط'\n",
    "            ,'زیر'\n",
    "            ,'اول'\n",
    "            ,'دوم'\n",
    "            ,'سوم'\n",
    "            ,'1'\n",
    "            ,'2'\n",
    "            ,'3'\n",
    "            ,'4'\n",
    "            ,'5'\n",
    "            ,'5'\n",
    "            ,'6'\n",
    "            ,'7'\n",
    "            ,'8'\n",
    "            ,'9'\n",
    "            ,'0'\n",
    "            ,'احمد'\n",
    "            ,'+'\n",
    "            ,'بهنام'\n",
    "            ,'مریم'\n",
    "            ,'نام'\n",
    "            ,'حسن'\n",
    "            ,'مورد'\n",
    "            ,'رو'\n",
    "            ,'ترین'\n",
    "            ,'شهناز'\n",
    "            ,'حسینی'\n",
    "            ,'لیلا'\n",
    "           ]\n",
    "s = '/Users/asma/ThirdUpdateNewsDataSet/'\n",
    "len(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newsbodytitle = []\n",
    "newsbodydict = dict()\n",
    "for add in address:\n",
    "    df = pd.read_csv(add + 'newsbodytitle.csv')\n",
    "    newsbodytitle.append(df)\n",
    "    newsbodydict[add] = df.ix[:,0]\n",
    "print len(newsbodydict)\n",
    "print len(newsbodytitle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normalizer = Normalizer()\n",
    "allnewssentence = dict()\n",
    "for key in newsbodydict:\n",
    "    sentences = []\n",
    "    for bod in newsbodydict[key]:\n",
    "        bod = normalizer.normalize(unicode(bod))\n",
    "        sentence = sent_tokenize(bod)\n",
    "        sentences.append(sentence)\n",
    "    print len(sentences)    \n",
    "    a = []\n",
    "    normsen = []\n",
    "    for par in sentences:\n",
    "        for sen in par:\n",
    "            a.append(list(word_tokenize(sen)))\n",
    "        normsen.append(a)\n",
    "        a = []\n",
    "    print len    \n",
    "    df = pd.DataFrame(normsen)\n",
    "    df.to_csv(os.path.join(key,'normsentences.csv'), index=False, encoding='utf-8')\n",
    "    allnewssentence[key] = normsen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from hazm import Lemmatizer, Stemmer\n",
    "import os\n",
    "stemmer = Stemmer()\n",
    "lemmatizer = Lemmatizer()\n",
    "eachnewsword = []\n",
    "helplist = []\n",
    "useless = []\n",
    "allnewsword = dict()\n",
    "for key in allnewssentence:\n",
    "    for sen in allnewssentence[key]:\n",
    "        for token in sen:\n",
    "            for w in token:\n",
    "                damn = False\n",
    "                for dw in damnword:\n",
    "                    if dw in w:\n",
    "                        damn = True\n",
    "                if 'های' in w[-3:]:\n",
    "                    w = stemmer.stem(w)\n",
    "                if 'ها' in w[-2:]:\n",
    "                    w = stemmer.stem(w)\n",
    "                if '-' in w:\n",
    "                    w = w.replace('-', ' ') \n",
    "                if '_' in w:\n",
    "                    w = w.replace('_',' ')\n",
    "                w = lemmatizer.lemmatize(w)    \n",
    "                if  damn or unicode.isnumeric(w) or ('*' in w) or ('/' in w) or ('#' in w) or ('@' in w) or  (len(w) <= 2) or  ('خواه' in w) or ('کرد' in w)  or ('است' in w) or ('ایرنا' in w) or ('گزارش' in w) or ('شد' in w) or ('شود' in w):\n",
    "                    useless.append(w)\n",
    "                else:\n",
    "                    helplist.append(w)\n",
    "        eachnewsword.append(helplist)\n",
    "        allnewsword[key] = eachnewsword\n",
    "        df = pd.DataFrame(eachnewsword)\n",
    "        df.to_csv(os.path.join(key,'eachnewsword.csv'), index=False, encoding='utf-8')\n",
    "        df1 = pd.DataFrame(useless)\n",
    "        df1.to_csv(os.path.join(key,'useless.csv'), index=False, encoding='utf-8') \n",
    "        helplist = []\n",
    "    eachnewsword = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hazm import Lemmatizer, Stemmer\n",
    "lemmatizer = Lemmatizer()\n",
    "print str(lemmatizer.lemmatize(unicode('اسما'))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
